{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg_covar = 1e-6\n",
    "tol = 1e-3\n",
    "def estimate_gaussian_covariances(resp, X, nk, means, reg_covar):\n",
    "    n_components, n_features = means.shape\n",
    "    covariances = np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]\n",
    "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        covariances[k].flat[::n_features + 1] += reg_covar\n",
    "    return covariances\n",
    "def compute_precision(covariances):\n",
    "    n_components, n_features, _ = covariances.shape\n",
    "    precisions = np.empty((n_components, n_features, n_features))\n",
    "    for k, covariance in enumerate(covariances):\n",
    "        try:\n",
    "            cov = linalg.cholesky(covariance, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(estimate_precision_error_message)\n",
    "        precisions[k] = linalg.solve_triangular(cov, np.eye(n_features), lower=True).T\n",
    "    return precisions\n",
    "def estimate_gaussian_parameters(X, resp, reg_covar):\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    covariances =  estimate_gaussian_covariances(resp, X, nk, means, reg_covar)\n",
    "    return nk, means, covariances\n",
    "def logsumexp(arr, axis=0):\n",
    "    arr = np.rollaxis(arr, axis)\n",
    "    # Use the max to normalize, as with the log this is what accumulates\n",
    "    # the less errors\n",
    "    vmax = arr.max(axis=0)\n",
    "    out = np.log(np.sum(np.exp(arr - vmax), axis=0))\n",
    "    out += vmax\n",
    "    return out\n",
    "def _compute_log_det(matrix,  n_features):\n",
    "\n",
    "    n_components, _, _ = matrix.shape\n",
    "    log_det = (np.sum(np.log(matrix.reshape(n_components, -1)[:, ::n_features + 1]), 1))\n",
    "\n",
    "    return log_det\n",
    "\n",
    "def _estimate_log_prob(X, means, precisions):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components, _ = means.shape\n",
    "    # det(precision_chol) is half of det(precision)\n",
    "    log_det = _compute_log_det(precisions, n_features)\n",
    "\n",
    "    log_prob = np.empty((n_samples, n_components))\n",
    "    for k, (mu, prec_chol) in enumerate(zip(means, precisions)):\n",
    "        y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
    "        log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
    "    return -.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
    "\n",
    "def _estimate_weighted_log_prob( X, means, precisions, weights):\n",
    "    return _estimate_log_prob(X, means, precisions) + np.log(weights)\n",
    "\n",
    "def _estimate_log_prob_resp( X, means, precisions, weights):\n",
    "    weighted_log_prob = _estimate_weighted_log_prob(X, means, precisions, weights)\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    with np.errstate(under='ignore'):\n",
    "        # ignore underflow\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    return log_prob_norm, log_resp\n",
    "\n",
    "def _e_step( X, means, precision, weights):\n",
    "    log_prob_norm, log_resp = _estimate_log_prob_resp(X, means, precision, weights)\n",
    "    return np.mean(log_prob_norm), log_resp\n",
    "def _m_step( X, log_resp, means, precisions, weights, covariances, reg_covar):\n",
    "    n_samples, _ = X.shape\n",
    "    weights, means, covariances = (estimate_gaussian_parameters(X, np.exp(log_resp),reg_covar))\n",
    "    weights /= n_samples\n",
    "    precisions1 = compute_precision(covariances)\n",
    "\n",
    "    # Attributes computation\n",
    "    _, n_features = means_.shape\n",
    "\n",
    "    precisions_ = np.empty(precisions1.shape)\n",
    "    for k, prec in enumerate(precisions1):\n",
    "        precisions_[k] = np.dot(prec, prec.T)\n",
    "        \n",
    "    return weights, means, covarinaces, precisions\n",
    "def initialize_parameters(X, random_state, k):\n",
    "    n_samples, _ = X.shape\n",
    "\n",
    "    resp = np.random.mtrand._rand.rand(n_samples, k)\n",
    "    resp /= resp.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    weights, means, covariances = estimate_gaussian_parameters(X, resp, reg_covar)\n",
    "    weights /= n_samples\n",
    "\n",
    "    precisions = compute_precision(covariances)\n",
    "    \n",
    "    return weights, means, covariances, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gmm(X, k, max_iter = 100):\n",
    "    predict = []\n",
    "    means = []\n",
    "    covariances = []\n",
    "\n",
    "    \n",
    "    \n",
    "    max_lower_bound = -np.infty\n",
    "    converged_ = False\n",
    "\n",
    "    random_state = None #check_random_state(random_state)\n",
    "\n",
    "    n_samples, _ = X.shape\n",
    "    \n",
    "    \n",
    "    weights, means, covarinaces, precisions = initialize_parameters(X, random_state, k)\n",
    "    lower_bound_ = -np.infty\n",
    "\n",
    "    for n_iter in range(max_iter):\n",
    "        prev_lower_bound = lower_bound_\n",
    "\n",
    "        log_prob_norm, log_resp = _e_step(X, means, precisions, weights)\n",
    "        weights, means, covarinaces, precisions = _m_step(X, log_resp, means, precisions, weights, covariances, reg_covar)\n",
    "        lower_bound_ =  log_prob_norm\n",
    "\n",
    "        change = lower_bound_ - prev_lower_bound\n",
    "\n",
    "        if abs(change) < tol:\n",
    "            converged_ = True\n",
    "            break\n",
    "        \n",
    "    predict = _estimate_weighted_log_prob(X, means, precisions, weights).argmax(axis=1)\n",
    "    return predict, means, covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'weights_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-af0c3f8193fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.scatter(data[:,0], data[:,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-edaf4e211ba1>\u001b[0m in \u001b[0;36mgmm\u001b[0;34m(X, k, max_iter)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprev_lower_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower_bound_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovarinaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlower_bound_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-ca2c34ef2572>\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(X, means, precision, weights)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_e_step\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_estimate_log_prob_resp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_m_step\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-ca2c34ef2572>\u001b[0m in \u001b[0;36m_estimate_log_prob_resp\u001b[0;34m(X, means, precisions, weights)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_log_prob_resp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mweighted_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_estimate_weighted_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mlog_prob_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_log_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-ca2c34ef2572>\u001b[0m in \u001b[0;36m_estimate_weighted_log_prob\u001b[0;34m(X, means, precisions, weights)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_weighted_log_prob\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_estimate_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_log_prob_resp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'weights_' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "data = sio.loadmat('q3.mat')['Xtest']\n",
    "#print data.shape\n",
    "#plt.scatter(data[:,0], data[:,1])\n",
    "\n",
    "predict, means, covariances = gmm(data, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
